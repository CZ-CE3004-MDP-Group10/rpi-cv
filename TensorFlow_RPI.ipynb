{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow-RPI",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyORgP7dyIddH01a6yxRzOpN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CZ-CE3004-MDP-Group10/rpi-cv/blob/main/TensorFlow_RPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdPIPNKHB1f3"
      },
      "source": [
        "# Setup Directory and Pathing Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRLwljH4Gjn7"
      },
      "source": [
        "## Mount Repository\r\n",
        "Start by mounting the repository, this repository contains the basic file structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXJUnN151zYg",
        "outputId": "4a1137c5-ba00-4be3-8139-0ef8843424b9"
      },
      "source": [
        "! git clone https://github.com/CZ-CE3004-MDP-Group10/rpi-cv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'rpi-cv' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2XjP1VN01XK"
      },
      "source": [
        "## Configure Environment Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgP9_u8Cqyr_"
      },
      "source": [
        "# copy labeled images and its XML files in PASCAL VOC \r\n",
        "%cp -a /content/rpi-cv/TensorFlow /content"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InQE0mhS1X6C"
      },
      "source": [
        "TENSORFLOW_PATH = '/content/TensorFlow'\r\n",
        "TF_API_MODEL_PATH = TENSORFLOW_PATH + '/models' \r\n",
        "SCRIPTS_PATH = TENSORFLOW_PATH + '/scripts'\r\n",
        "WORKSPACE_PATH = TENSORFLOW_PATH + '/workspace'\r\n",
        "ANNOTATIONS_PATH = WORKSPACE_PATH + '/annotations'\r\n",
        "EXPORTED_MODELS_PATH = WORKSPACE_PATH + '/exported-models'\r\n",
        "MODEL_PATH = WORKSPACE_PATH + '/models'\r\n",
        "IMAGES_PATH = WORKSPACE_PATH +'/images'\r\n",
        "PRE_TRAINED_MODELS_PATH = WORKSPACE_PATH +'/pre-trained-models'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9CbaZNjjHh4"
      },
      "source": [
        "## Mount TensorFlow Model Garden\r\n",
        "In order to use the TensorFlow Object Detection API, we need to clone it's GitHub Repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "02ICz9sugTTG",
        "outputId": "383041ef-abe7-4fd9-baf8-e4007fe973be"
      },
      "source": [
        "import os\r\n",
        "os.chdir(TENSORFLOW_PATH)\r\n",
        "os.getcwd()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-12de3f499dd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTENSORFLOW_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/TensorFlow-RPI'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F62iHIpQfRrR"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhSKvoN2Bxl3"
      },
      "source": [
        "# Install Required Libraries and Tools\r\n",
        "With colab, TensorFlow is already pre-installed along with its other dependencies. \r\n",
        "\r\n",
        "However, the TensorFlow Object Detection API relies on what are called protocol buffers (also known as protobufs). Protobufs are a language neutral way to describe information. That means you can write a protobuf once and then compile it to be used with other languages, like Python, Java or C."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IIgjazXt3A8"
      },
      "source": [
        "!apt-get install protobuf-compiler python-lxml python-pil\r\n",
        "!pip install Cython pandas tf-slim lvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39KueoA7t5tH"
      },
      "source": [
        "## Compile and Install the Protobuf libraries\r\n",
        "The protoc command used below is compiling all the protocol buffers in the object_detection/protos folder for Python. Environment\r\n",
        "\r\n",
        "To use the object detection api we need to add it to our PYTHONPATH along with slim which contains code for training and evaluating several widely used Convolutional Neural Network (CNN) image classification models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3qaeGCI2r3b"
      },
      "source": [
        "import os\r\n",
        "os.chdir(TENSORFLOW_PATH + '/models/research/')\r\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ilw3kjmet43f"
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZh2xQftuaMt"
      },
      "source": [
        "## Set the Tensrflow Object Detection Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZGfesE4ufNs"
      },
      "source": [
        "import os\r\n",
        "import sys\r\n",
        "os.environ['PYTHONPATH'] += \":/content/TensorFlow-RPI/models\"\r\n",
        "print(os.environ['PYTHONPATH'])\r\n",
        "\r\n",
        "sys.path.append('/content/TensorFlow-RPI/models/research')\r\n",
        "print(sys.path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePhgSPnZ4_x5"
      },
      "source": [
        "## Build and Install the TensorFlow Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_upDBBDuB8n"
      },
      "source": [
        "!python slim/setup.py build\r\n",
        "!python slim/setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrkyR3qzFVfC"
      },
      "source": [
        "## Test Tensorflow 2 Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfwv37vs7Cto"
      },
      "source": [
        "#cd into 'TensorFlow/models/research/object_detection/builders/'\r\n",
        "%cd '/content/TensorFlow-RPI/models/research/object_detection/builders/'\r\n",
        "!python model_builder_tf2_test.py\r\n",
        "from object_detection.utils import label_map_util\r\n",
        "from object_detection.utils import visualization_utils as viz_utils\r\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhOOS_3DFidr"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr1C2oEFHU8m"
      },
      "source": [
        "## 1. Label Image with Imagelabel\r\n",
        "Split 80/20 image for training and testing. Then label the image according to their appropriate signs.\r\n",
        "\r\n",
        "We used https://github.com/tzutalin/labelImg the image labeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exzSaiSpotwp"
      },
      "source": [
        "## 2. Create Label Map\r\n",
        "TensorFlow requires a label map, which namely maps each of the used labels to an integer values. This label map is used both by the training and detection processes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZQuMD81o0Hu"
      },
      "source": [
        "labels = [\r\n",
        "    {'name':'0', 'id':1}, \r\n",
        "    {'name':'6', 'id':2}, \r\n",
        "    {'name':'7', 'id':3}, \r\n",
        "    {'name':'8', 'id':4}, \r\n",
        "    {'name':'9', 'id':5}, \r\n",
        "    {'name':'circle', 'id':6},\r\n",
        "    {'name':'up', 'id':7}, \r\n",
        "    {'name':'down', 'id':8}, \r\n",
        "    {'name':'left', 'id':9}, \r\n",
        "    {'name':'right', 'id':10}, \r\n",
        "    {'name':'v', 'id':11}, \r\n",
        "    {'name':'w', 'id':12}, \r\n",
        "    {'name':'x', 'id':13}, \r\n",
        "    {'name':'y', 'id':14}, \r\n",
        "    {'name':'z', 'id':15}\r\n",
        "]\r\n",
        "\r\n",
        "with open(ANNOTATIONS_PATH+'/label_map.pbtxt', 'w') as f:\r\n",
        "    for label in labels:\r\n",
        "        f.write('item { \\n')\r\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\r\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\r\n",
        "        f.write('}\\n')\r\n",
        "\r\n",
        "# !cat label_map.pbtxt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u83ZmiKlqbxI"
      },
      "source": [
        "## 3. Create TensorFlow Records\r\n",
        "\r\n",
        "Now that we have generated our annotations and split our dataset into the desired training and testing subsets, it is time to convert our annotations into the so called TFRecord format.\r\n",
        "Convert *.xml to *.record\r\n",
        "\r\n",
        "To do this we can write a simple script that iterates through all *.xml files in the training_demo/images/train and training_demo/images/test folders, and generates a *.record file for each of the two. Here is an example script that allows us to do just that:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-hWNC_2qgdJ"
      },
      "source": [
        "# Create train data:\r\n",
        "!python {SCRIPTS_PATH + '/preprocessing/generate_tfrecord.py'} -x {IMAGES_PATH + '/train'} -l {ANNOTATIONS_PATH + '/label_map.pbtxt'} -o {ANNOTATIONS_PATH + '/train.record'}\r\n",
        "# Create test data:\r\n",
        "!python {SCRIPTS_PATH + '/preprocessing/generate_tfrecord.py'} -x {IMAGES_PATH + '/test'} -l {ANNOTATIONS_PATH + '/label_map.pbtxt'} -o {ANNOTATIONS_PATH + '/test.record'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNFb0mthbUL0"
      },
      "source": [
        "## 4. Download Pre-Trained Model\r\n",
        "To begin with, we need to download the latest pre-trained network for the model we wish to use. \r\n",
        "\r\n",
        "This can be done by simply clicking on the name of the desired model in the table found in [TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). Clicking on the name of your model should initiate a download for a `*.tar.gz` file.\r\n",
        "\r\n",
        "Once the `*.tar.gz` file has been downloaded, open it using a decompression program of your choice (e.g. 7zip, WinZIP, etc.). Next, open the `*.tar` folder that you see when the compressed folder is opened, and extract its contents inside the folder `/workspace/pre-trained-models`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsW-v715ftDz"
      },
      "source": [
        "import os\r\n",
        "# import urllib.request\r\n",
        "import requests\r\n",
        "import tarfile\r\n",
        "\r\n",
        "from shutil import copyfile\r\n",
        "\r\n",
        "\r\n",
        "os.chdir(PRE_TRAINED_MODELS_PATH)\r\n",
        "base_url = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/\"\r\n",
        "models = [\r\n",
        "          \"ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\",\r\n",
        "          # \"faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\"\r\n",
        "]\r\n",
        "\r\n",
        "for model in models:\r\n",
        "  url = base_url + model\r\n",
        "  r = requests.get(url, allow_redirects=True)\r\n",
        "  open(model, 'wb').write(r.content)\r\n",
        "  tar = tarfile.open(model)\r\n",
        "  tar.extractall()\r\n",
        "  tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwavK8KUK2iD"
      },
      "source": [
        "## 4. Copy Choosen Model to Training folder\r\n",
        "Finally, the object detection training pipeline must be configured. It defines which model and what parameters will be used for training. This is the last step before running training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51esqZC9L823"
      },
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet_v2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c_dmb9lQce0"
      },
      "source": [
        "import os\r\n",
        "from shutil import copyfile\r\n",
        "\r\n",
        "os.chdir(WORKSPACE_PATH)\r\n",
        "os.mkdir(MODEL_PATH + '/' + CUSTOM_MODEL_NAME)\r\n",
        "copyfile(PRE_TRAINED_MODELS_PATH+'/ssd_mobilenet_v2_320x320_coco17_tpu-8/pipeline.config', MODEL_PATH + '/' + CUSTOM_MODEL_NAME + '/pipeline.config')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEPrGFmfWgi3"
      },
      "source": [
        "!cat /content/TensorFlow-RPI/workspace/models/my_ssd_mobnet_v2/pipeline.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GygVpScXZKu"
      },
      "source": [
        "## 5. Updating Choosen Model Config file\r\n",
        "There will be multiple parameters that needs to be configured for the config file prior to training. We will use a Python script to shorten the process.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26n3VzuTZAmi"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from object_detection.utils import config_util\r\n",
        "from object_detection.protos import pipeline_pb2\r\n",
        "from google.protobuf import text_format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-GgPm4eZFhI"
      },
      "source": [
        "CONFIG_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME+'/pipeline.config'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUjycEqNZL4t"
      },
      "source": [
        "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0tUXV78ZP3G"
      },
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\r\n",
        "with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:                                                                                                                                                                                                                     \r\n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \r\n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljUWROs6ZVbp"
      },
      "source": [
        "# Number of label classes\r\n",
        "pipeline_config.model.ssd.num_classes = 15\r\n",
        "# Number of images\r\n",
        "pipeline_config.train_config.batch_size = 15 \r\n",
        "# Model checkpoint (Checkpoints capture the exact value of all parameters (tf.Variable objects) used by a model)\r\n",
        "pipeline_config.train_config.fine_tune_checkpoint = PRE_TRAINED_MODELS_PATH + '/ssd_mobilenet_v2_320x320_coco17_tpu-8/checkpoint/ckpt-0' \r\n",
        "# Specify to train DETECTION model\r\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\r\n",
        "# Label map for train\r\n",
        "pipeline_config.train_input_reader.label_map_path= ANNOTATIONS_PATH + '/label_map.pbtxt'\r\n",
        "# TF records of train\r\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [ANNOTATIONS_PATH + '/train.record']\r\n",
        "# Label map for test\r\n",
        "pipeline_config.eval_input_reader[0].label_map_path = ANNOTATIONS_PATH + '/label_map.pbtxt'\r\n",
        "# TF reocrds of test\r\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [ANNOTATIONS_PATH + '/test.record']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCF9YHv9bZ1g"
      },
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \r\n",
        "with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:                                                                                                                                                                                                                     \r\n",
        "    f.write(config_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebqCYfzabf6b"
      },
      "source": [
        "!cat /content/TensorFlow-RPI/workspace/models/my_ssd_mobnet_v2/pipeline.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku2StgFgcWy5"
      },
      "source": [
        "## Train the Model\r\n",
        "Note TensorFlow 2 is used\r\n",
        "Number of training steps can be configured to suit the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai8YrnTbbi9O"
      },
      "source": [
        "# --num_train_steps=5000\r\n",
        "print(\"\"\"!python {}/research/object_detection/model_main_tf2.py --model_dir={}/{} --pipeline_config_path={}/{}/pipeline.config \"\"\".format(TF_API_MODEL_PATH, MODEL_PATH,CUSTOM_MODEL_NAME,MODEL_PATH,CUSTOM_MODEL_NAME))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTEJrBdjdUX-"
      },
      "source": [
        "# run the printed statement ^^^^\r\n",
        "!python /content/TensorFlow-RPI/models/research/object_detection/model_main_tf2.py --model_dir=/content/TensorFlow-RPI/workspace/models/my_ssd_mobnet_v2 --pipeline_config_path=/content/TensorFlow-RPI/workspace/models/my_ssd_mobnet_v2/pipeline.config \r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}