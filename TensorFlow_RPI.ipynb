{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow-RPI",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMiTov5mb3XbNTl4SLXbWsB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CZ-CE3004-MDP-Group10/rpi-cv/blob/main/TensorFlow_RPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdPIPNKHB1f3"
      },
      "source": [
        "# Setup Directory and Pathing Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRLwljH4Gjn7"
      },
      "source": [
        "## Mount Repository\r\n",
        "Start by mounting the repository, this repository contains the basic file structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXJUnN151zYg",
        "outputId": "ee21b289-7676-465c-a398-0d8ebd00784c"
      },
      "source": [
        "! git clone --depth 1 https://github.com/CZ-CE3004-MDP-Group10/rpi-cv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'rpi-cv'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 44 (delta 14), reused 40 (delta 14), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2XjP1VN01XK"
      },
      "source": [
        "## Configure Environment Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgP9_u8Cqyr_"
      },
      "source": [
        "# copy labeled images and its XML files in PASCAL VOC \r\n",
        "%cp -a /content/rpi-cv/TensorFlow /content"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InQE0mhS1X6C"
      },
      "source": [
        "TENSORFLOW_PATH = '/content/TensorFlow'\r\n",
        "TF_API_MODEL_PATH = TENSORFLOW_PATH + '/models' \r\n",
        "SCRIPTS_PATH = TENSORFLOW_PATH + '/scripts'\r\n",
        "WORKSPACE_PATH = TENSORFLOW_PATH + '/workspace'\r\n",
        "ANNOTATIONS_PATH = WORKSPACE_PATH + '/annotations'\r\n",
        "IMAGES_PATH = WORKSPACE_PATH +'/images'\r\n",
        "EXPORTED_MODELS_PATH = WORKSPACE_PATH + '/exported-models'\r\n",
        "MODEL_PATH = WORKSPACE_PATH + '/models'\r\n",
        "PRE_TRAINED_MODELS_PATH = WORKSPACE_PATH +'/pre-trained-models'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP4Wt1U4on7i"
      },
      "source": [
        "!mkdir {EXPORTED_MODELS_PATH}\r\n",
        "!mkdir {MODEL_PATH}\r\n",
        "!mkdir {PRE_TRAINED_MODELS_PATH}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9CbaZNjjHh4"
      },
      "source": [
        "## Mount TensorFlow Model Garden\r\n",
        "In order to use the TensorFlow Object Detection API, we need to clone it's GitHub Repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "02ICz9sugTTG",
        "outputId": "fcadb43e-4ddd-487b-a5ed-8125e55339b3"
      },
      "source": [
        "import os\r\n",
        "os.chdir(TENSORFLOW_PATH)\r\n",
        "os.getcwd()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/TensorFlow'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F62iHIpQfRrR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f24cf3dd-e036-4589-f9ee-d16eaa55036a"
      },
      "source": [
        "!git clone --depth 1 https://github.com/tensorflow/models.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2416, done.\u001b[K\n",
            "remote: Counting objects: 100% (2416/2416), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2020/2020), done.\u001b[K\n",
            "remote: Total 2416 (delta 575), reused 1376 (delta 368), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2416/2416), 30.79 MiB | 38.78 MiB/s, done.\n",
            "Resolving deltas: 100% (575/575), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZh2xQftuaMt"
      },
      "source": [
        "## Set up TensorFlow Object Detection Environment\r\n",
        "To use the object detection api we need to add it to our PYTHONPATH along with slim which contains code for training and evaluating several widely used Convolutional Neural Network (CNN) image classification models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZGfesE4ufNs",
        "outputId": "4bbe873e-203f-4ab0-edb0-aeb6ffc2e8f7"
      },
      "source": [
        "import os\r\n",
        "import sys\r\n",
        "os.environ['PYTHONPATH'] += \":/content/TensorFlow/models\"\r\n",
        "print(os.environ['PYTHONPATH'])\r\n",
        "\r\n",
        "sys.path.append('/content/TensorFlow/models/research')\r\n",
        "print(sys.path)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/env/python:/content/TensorFlow/models\n",
            "['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/content/TensorFlow/models/research']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhSKvoN2Bxl3"
      },
      "source": [
        "# Install Required Libraries and Tools\r\n",
        "With colab, TensorFlow is already pre-installed along with its other dependencies. \r\n",
        "\r\n",
        "However, the TensorFlow Object Detection API relies on what are called protocol buffers (also known as protobufs). Protobufs are a language neutral way to describe information. That means you can write a protobuf once and then compile it to be used with other languages, like Python, Java or C."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLcvWIbctGUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab7fbe0-9754-4624-85d1-e675aeea329e"
      },
      "source": [
        "!sudo apt install -y protobuf-compiler"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 17 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePhgSPnZ4_x5"
      },
      "source": [
        "## Build and Install the TensorFlow Object Detection API\r\n",
        "The protoc command used below is compiling all the protocol buffers in the object_detection/protos folder for Python. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUspRPI7qRuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0238220-14a6-4d3c-c035-1bcb026819e7"
      },
      "source": [
        "%%bash\r\n",
        "cd /content/TensorFlow/models/research\r\n",
        "# Compile and build the TF2 OD setup.py\r\n",
        "protoc object_detection/protos/*.proto --python_out=.\r\n",
        "cp object_detection/packages/tf2/setup.py .\r\n",
        "# install TF2 OD API\r\n",
        "python -m pip install ."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/TensorFlow/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/84/ef37f882a7d93674d6fe1aa6e99f18cf2f34e9b775952f3d85587c11c92e/avro-python3-1.10.1.tar.gz\n",
            "Collecting apache-beam\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/f8/afcd9a457d92bd7858df5ece8f8ecae7d7387fbbb6e3438c6cb495278743/apache_beam-2.27.0-cp36-cp36m-manylinux2010_x86_64.whl (9.0MB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.21)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official\n",
            "  Downloading https://files.pythonhosted.org/packages/57/4a/23a08f8fd2747867ee223612e219eeb0d11c36116601d99b55ef3c72e707/tf_models_official-2.4.0-py2.py3-none-any.whl (1.1MB)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.11.3)\n",
            "Collecting requests<3.0.0,>=2.24.0\n",
            "  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
            "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n",
            "Collecting pyarrow<3.0.0,>=0.15.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n",
            "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.32.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/08/f7/4c3fad73123a24d7394b6f40d1ec9c1cbf2e921cfea1797216ffd0a51fb1/hdfs-2.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: numpy<2,>=1.14.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
            "Collecting mock<3.0.0,>=1.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
            "Collecting future<1.0.0,>=0.18.2\n",
            "  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/de/b97ba22868817c021705fd9e3376530fbc0e4a575fa3d0a78492d6f980e3/fastavro-1.3.2-cp36-cp36m-manylinux2014_x86_64.whl (2.2MB)\n",
            "Requirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->object-detection==0.1) (53.0.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.5.10)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading https://files.pythonhosted.org/packages/96/fc/4da675cc522a749ebbcf85c5a63fba844b2d44c87e6f24e3fdb147df3270/opencv_python_headless-4.5.1.48-cp36-cp36m-manylinux2014_x86_64.whl (37.6MB)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.7.12)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "Requirement already satisfied: tensorflow>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.4.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/5b/bc0b5ab38247bba158504a410112b6c03f153c652734ece1849749e5f518/PyYAML-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (640kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/af/0ce633c373d2b0476ef8299673d22275fcc3c5ba283b2cec4aa06bc5b810/tensorflow_addons-0.12.1-cp36-cp36m-manylinux2010_x86_64.whl (703kB)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/f5/8e6e85ce2e9f6e05040cf0d4e26f43a4718bcc4bce988b433276d4b1a5c1/py-cpuinfo-7.0.0.tar.gz (95kB)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.12.5)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Collecting pbr>=0.11\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.25.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official->object-detection==0.1) (0.1.5)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.4.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.10.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.1.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.27.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (20.3.0)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.52.0)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
            "Building wheels for collected packages: object-detection, avro-python3, dill, future, seqeval, py-cpuinfo\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1618454 sha256=60c34d5eb3566e95a68b0e9e837da3ef3da9519ec47c97c668e595f37f6f2dbe\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5i70bqnt/wheels/1e/a6/ce/339480921228eb089bee0cdaf7efbaa7b5cf803ec6420ab905\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.1-cp36-none-any.whl size=43734 sha256=5593a0bd43e38a2612696a5470156fdf7c34b5ef281005a92c62f69f0daad79f\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/fe/90/20d6d6d97223d80d20cb390be636619c536edab5658c12bdba\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-cp36-none-any.whl size=78533 sha256=775e339c975ec8339baf74aa74ddc7bbfebac10b2647badf553c2ef400a93922\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
            "  Building wheel for future (setup.py): started\n",
            "  Building wheel for future (setup.py): finished with status 'done'\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=3ad901bcf5260648b4ca01697218be8813e3a466dd31c47ff301f6e61630af5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=f12b4df925001db9c71cc8c124726922a6122c8f1fefec7b35c81ade24403ebc\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "  Building wheel for py-cpuinfo (setup.py): started\n",
            "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-7.0.0-cp36-none-any.whl size=20072 sha256=320839f1956ba944bcfac9a34f73aa694155ccdbca1e9193b5ed01500ee24f42\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/93/7b/127daf0c3a5a49feb2fecd468d508067c733fba5192f726ad1\n",
            "Successfully built object-detection avro-python3 dill future seqeval py-cpuinfo\n",
            "Installing collected packages: avro-python3, requests, dill, pyarrow, hdfs, pbr, mock, future, fastavro, apache-beam, tf-slim, lvis, opencv-python-headless, tensorflow-model-optimization, pyyaml, sentencepiece, tensorflow-addons, seqeval, py-cpuinfo, tf-models-official, object-detection\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: dill 0.3.3\n",
            "    Uninstalling dill-0.3.3:\n",
            "      Successfully uninstalled dill-0.3.3\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed apache-beam-2.27.0 avro-python3-1.10.1 dill-0.3.1.1 fastavro-1.3.2 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 mock-2.0.0 object-detection-0.1 opencv-python-headless-4.5.1.48 pbr-5.5.1 py-cpuinfo-7.0.0 pyarrow-2.0.0 pyyaml-5.4.1 requests-2.25.1 sentencepiece-0.1.95 seqeval-1.2.2 tensorflow-addons-0.12.1 tensorflow-model-optimization-0.5.0 tf-models-official-2.4.0 tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR: multiprocess 0.70.11.1 has requirement dill>=0.3.3, but you'll have dill 0.3.1.1 which is incompatible.\n",
            "ERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\n",
            "ERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\n",
            "ERROR: apache-beam 2.27.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.1 which is incompatible.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrkyR3qzFVfC"
      },
      "source": [
        "## Test Tensorflow 2 Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfwv37vs7Cto",
        "outputId": "eb6cdebf-e174-4c38-8b5a-bc1efe6accd6"
      },
      "source": [
        "#cd into 'TensorFlow/models/research/object_detection/builders/'\r\n",
        "%cd '/content/TensorFlow/models/research/object_detection/builders'\r\n",
        "!python model_builder_tf2_test.py\r\n",
        "from object_detection.utils import label_map_util\r\n",
        "from object_detection.utils import visualization_utils as viz_utils\r\n",
        "print('Done')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TensorFlow/models/research/object_detection/builders\n",
            "2021-02-16 07:59:10.652338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "Running tests under Python 3.6.9: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model\n",
            "2021-02-16 07:59:13.436626: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-02-16 07:59:13.437702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-02-16 07:59:13.502101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 07:59:13.502705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-02-16 07:59:13.502743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-16 07:59:13.734058: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
            "2021-02-16 07:59:13.734191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
            "2021-02-16 07:59:13.848355: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-02-16 07:59:13.862579: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-02-16 07:59:14.154368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-02-16 07:59:14.216786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-02-16 07:59:14.726333: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-16 07:59:14.726547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 07:59:14.727268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 07:59:14.730238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-02-16 07:59:14.730765: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-02-16 07:59:14.730915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 07:59:14.731493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-02-16 07:59:14.731538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-16 07:59:14.731616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
            "2021-02-16 07:59:14.731641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
            "2021-02-16 07:59:14.731675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-02-16 07:59:14.731701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-02-16 07:59:14.731726: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-02-16 07:59:14.731745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-02-16 07:59:14.731765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-16 07:59:14.731843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 07:59:14.732420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 07:59:14.732961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-02-16 07:59:14.734869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-16 07:59:18.732160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-02-16 07:59:18.732208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-02-16 07:59:18.732224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-02-16 07:59:18.737193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 07:59:18.737938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 07:59:18.738551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 07:59:18.739109: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-02-16 07:59:18.739160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13994 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 8.11s\n",
            "I0216 07:59:21.357458 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_center_net_model): 8.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0216 07:59:21.358485 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "I0216 07:59:21.400897 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0216 07:59:21.421597 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0216 07:59:21.442472 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.14s\n",
            "I0216 07:59:21.580897 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.15s\n",
            "I0216 07:59:21.732117 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "I0216 07:59:21.871420 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "I0216 07:59:22.016268 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.15s\n",
            "I0216 07:59:22.162884 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
            "I0216 07:59:22.208614 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0216 07:59:22.621219 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0216 07:59:22.621395 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 64\n",
            "I0216 07:59:22.621470 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 3\n",
            "I0216 07:59:22.626576 140339062957952 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0216 07:59:22.643098 140339062957952 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0216 07:59:22.643233 140339062957952 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0216 07:59:22.699643 140339062957952 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0216 07:59:22.699780 140339062957952 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0216 07:59:22.847120 140339062957952 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0216 07:59:22.847304 140339062957952 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0216 07:59:22.993499 140339062957952 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0216 07:59:22.993684 140339062957952 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0216 07:59:23.204119 140339062957952 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0216 07:59:23.204370 140339062957952 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0216 07:59:23.418163 140339062957952 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0216 07:59:23.418336 140339062957952 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0216 07:59:23.701009 140339062957952 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0216 07:59:23.701177 140339062957952 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0216 07:59:23.766886 140339062957952 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0216 07:59:23.793220 140339062957952 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0216 07:59:23.865087 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0216 07:59:23.865234 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 88\n",
            "I0216 07:59:23.865310 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 4\n",
            "I0216 07:59:23.869829 140339062957952 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0216 07:59:23.883521 140339062957952 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0216 07:59:23.883972 140339062957952 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0216 07:59:24.003139 140339062957952 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0216 07:59:24.003312 140339062957952 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0216 07:59:24.216865 140339062957952 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0216 07:59:24.217039 140339062957952 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0216 07:59:24.430969 140339062957952 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0216 07:59:24.431144 140339062957952 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0216 07:59:24.708225 140339062957952 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0216 07:59:24.708411 140339062957952 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0216 07:59:24.991209 140339062957952 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0216 07:59:24.991424 140339062957952 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0216 07:59:25.450129 140339062957952 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0216 07:59:25.450303 140339062957952 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0216 07:59:25.586428 140339062957952 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0216 07:59:25.611349 140339062957952 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0216 07:59:25.689035 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0216 07:59:25.689209 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 112\n",
            "I0216 07:59:25.689282 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 5\n",
            "I0216 07:59:25.693304 140339062957952 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0216 07:59:25.707317 140339062957952 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0216 07:59:25.707443 140339062957952 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0216 07:59:25.820044 140339062957952 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0216 07:59:25.820203 140339062957952 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0216 07:59:26.030776 140339062957952 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0216 07:59:26.030951 140339062957952 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0216 07:59:26.241093 140339062957952 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0216 07:59:26.241266 140339062957952 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0216 07:59:26.521155 140339062957952 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0216 07:59:26.521329 140339062957952 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0216 07:59:26.809451 140339062957952 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0216 07:59:26.809631 140339062957952 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0216 07:59:27.161796 140339062957952 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0216 07:59:27.161961 140339062957952 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I0216 07:59:27.296609 140339062957952 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I0216 07:59:27.321372 140339062957952 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0216 07:59:27.397335 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0216 07:59:27.397508 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 160\n",
            "I0216 07:59:27.397590 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 6\n",
            "I0216 07:59:27.401734 140339062957952 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0216 07:59:27.416330 140339062957952 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0216 07:59:27.416480 140339062957952 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0216 07:59:27.536735 140339062957952 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0216 07:59:27.536902 140339062957952 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0216 07:59:27.739064 140339062957952 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0216 07:59:27.739236 140339062957952 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0216 07:59:27.946898 140339062957952 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0216 07:59:27.947076 140339062957952 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0216 07:59:28.300740 140339062957952 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0216 07:59:28.300923 140339062957952 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0216 07:59:28.688310 140339062957952 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0216 07:59:28.688484 140339062957952 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0216 07:59:29.280558 140339062957952 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0216 07:59:29.280756 140339062957952 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I0216 07:59:29.429437 140339062957952 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I0216 07:59:29.453789 140339062957952 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0216 07:59:29.533162 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0216 07:59:29.533309 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 224\n",
            "I0216 07:59:29.533382 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n",
            "I0216 07:59:29.537560 140339062957952 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0216 07:59:29.551490 140339062957952 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0216 07:59:29.551625 140339062957952 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0216 07:59:29.662217 140339062957952 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0216 07:59:29.662372 140339062957952 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0216 07:59:29.938112 140339062957952 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0216 07:59:29.938277 140339062957952 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0216 07:59:30.223405 140339062957952 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0216 07:59:30.223606 140339062957952 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0216 07:59:30.654724 140339062957952 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0216 07:59:30.654897 140339062957952 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0216 07:59:31.076225 140339062957952 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0216 07:59:31.076391 140339062957952 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0216 07:59:31.630344 140339062957952 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0216 07:59:31.630519 140339062957952 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I0216 07:59:31.768058 140339062957952 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I0216 07:59:31.793152 140339062957952 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0216 07:59:31.887597 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0216 07:59:31.887755 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 288\n",
            "I0216 07:59:31.887826 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n",
            "I0216 07:59:31.892120 140339062957952 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0216 07:59:31.906897 140339062957952 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0216 07:59:31.907032 140339062957952 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0216 07:59:32.081886 140339062957952 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0216 07:59:32.082095 140339062957952 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0216 07:59:32.442945 140339062957952 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0216 07:59:32.443126 140339062957952 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0216 07:59:32.967717 140339062957952 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0216 07:59:32.967885 140339062957952 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0216 07:59:33.451443 140339062957952 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0216 07:59:33.451629 140339062957952 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0216 07:59:33.929588 140339062957952 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0216 07:59:33.929764 140339062957952 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0216 07:59:34.558099 140339062957952 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0216 07:59:34.558280 140339062957952 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I0216 07:59:34.779749 140339062957952 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I0216 07:59:34.808922 140339062957952 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0216 07:59:34.911270 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0216 07:59:34.911437 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n",
            "I0216 07:59:34.911522 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n",
            "I0216 07:59:34.915686 140339062957952 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0216 07:59:34.929965 140339062957952 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0216 07:59:34.930078 140339062957952 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0216 07:59:35.097878 140339062957952 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0216 07:59:35.098053 140339062957952 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0216 07:59:35.513087 140339062957952 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0216 07:59:35.513249 140339062957952 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0216 07:59:35.923749 140339062957952 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0216 07:59:35.923913 140339062957952 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0216 07:59:36.644459 140339062957952 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0216 07:59:36.644651 140339062957952 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0216 07:59:37.209312 140339062957952 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0216 07:59:37.209488 140339062957952 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0216 07:59:37.972766 140339062957952 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0216 07:59:37.972932 140339062957952 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I0216 07:59:38.177428 140339062957952 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I0216 07:59:38.201313 140339062957952 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0216 07:59:38.318618 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0216 07:59:38.318791 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n",
            "I0216 07:59:38.318865 140339062957952 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n",
            "I0216 07:59:38.323120 140339062957952 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0216 07:59:38.337605 140339062957952 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0216 07:59:38.337746 140339062957952 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0216 07:59:38.563033 140339062957952 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0216 07:59:38.563197 140339062957952 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0216 07:59:39.047232 140339062957952 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0216 07:59:39.047451 140339062957952 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0216 07:59:39.533914 140339062957952 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0216 07:59:39.534091 140339062957952 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0216 07:59:40.238609 140339062957952 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0216 07:59:40.238782 140339062957952 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0216 07:59:41.109789 140339062957952 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0216 07:59:41.109956 140339062957952 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0216 07:59:42.025503 140339062957952 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0216 07:59:42.025691 140339062957952 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I0216 07:59:42.303738 140339062957952 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I0216 07:59:42.337733 140339062957952 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 20.25s\n",
            "I0216 07:59:42.462983 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 20.25s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0216 07:59:42.469064 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0216 07:59:42.470634 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0216 07:59:42.471096 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0216 07:59:42.472500 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0216 07:59:42.473790 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0216 07:59:42.474173 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0216 07:59:42.475073 140339062957952 test_util.py:2076] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 20 tests in 29.230s\n",
            "\n",
            "OK (skipped=1)\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhOOS_3DFidr"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr1C2oEFHU8m"
      },
      "source": [
        "## 1. Label Image with Imagelabel\r\n",
        "Split 80/20 image for training and testing. Then label the image according to their appropriate signs.\r\n",
        "\r\n",
        "We used https://github.com/tzutalin/labelImg the image labeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exzSaiSpotwp"
      },
      "source": [
        "## 2. Create Label Map\r\n",
        "TensorFlow requires a label map, which namely maps each of the used labels to an integer values. This label map is used both by the training and detection processes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZQuMD81o0Hu"
      },
      "source": [
        "labels = [\r\n",
        "    {'name':'0', 'id':1}, \r\n",
        "    {'name':'6', 'id':2}, \r\n",
        "    {'name':'7', 'id':3}, \r\n",
        "    {'name':'8', 'id':4}, \r\n",
        "    {'name':'9', 'id':5}, \r\n",
        "    {'name':'circle', 'id':6},\r\n",
        "    {'name':'up', 'id':7}, \r\n",
        "    {'name':'down', 'id':8}, \r\n",
        "    {'name':'left', 'id':9}, \r\n",
        "    {'name':'right', 'id':10}, \r\n",
        "    {'name':'v', 'id':11}, \r\n",
        "    {'name':'w', 'id':12}, \r\n",
        "    {'name':'x', 'id':13}, \r\n",
        "    {'name':'y', 'id':14}, \r\n",
        "    {'name':'z', 'id':15}\r\n",
        "]\r\n",
        "\r\n",
        "with open(ANNOTATIONS_PATH+'/label_map.pbtxt', 'w') as f:\r\n",
        "    for label in labels:\r\n",
        "        f.write('item { \\n')\r\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\r\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\r\n",
        "        f.write('}\\n')\r\n",
        "\r\n",
        "# !cat label_map.pbtxt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u83ZmiKlqbxI"
      },
      "source": [
        "## 3. Create TensorFlow Records\r\n",
        "\r\n",
        "Now that we have generated our annotations and split our dataset into the desired training and testing subsets, it is time to convert our annotations into the so called TFRecord format.\r\n",
        "Convert *.xml to *.record\r\n",
        "\r\n",
        "To do this we can write a simple script that iterates through all *.xml files in the training_demo/images/train and training_demo/images/test folders, and generates a *.record file for each of the two. Here is an example script that allows us to do just that:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-hWNC_2qgdJ",
        "outputId": "e8dc5996-e319-4602-8b48-8dc6c77fe578"
      },
      "source": [
        "# Create train data:\r\n",
        "!python {SCRIPTS_PATH + '/preprocessing/generate_tfrecord.py'} -x {IMAGES_PATH + '/train'} -l {ANNOTATIONS_PATH + '/label_map.pbtxt'} -o {ANNOTATIONS_PATH + '/train.record'}\r\n",
        "# Create test data:\r\n",
        "!python {SCRIPTS_PATH + '/preprocessing/generate_tfrecord.py'} -x {IMAGES_PATH + '/test'} -l {ANNOTATIONS_PATH + '/label_map.pbtxt'} -o {ANNOTATIONS_PATH + '/test.record'}"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: /content/TensorFlow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: /content/TensorFlow/workspace/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNFb0mthbUL0"
      },
      "source": [
        "## 4. Download Pre-Trained Model\r\n",
        "To begin with, we need to download the latest pre-trained network for the model we wish to use. \r\n",
        "\r\n",
        "This can be done by simply clicking on the name of the desired model in the table found in [TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). Clicking on the name of your model should initiate a download for a `*.tar.gz` file.\r\n",
        "\r\n",
        "Once the `*.tar.gz` file has been downloaded, open it using a decompression program of your choice (e.g. 7zip, WinZIP, etc.). Next, open the `*.tar` folder that you see when the compressed folder is opened, and extract its contents inside the folder `/workspace/pre-trained-models`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsW-v715ftDz"
      },
      "source": [
        "import os\r\n",
        "# import urllib.request\r\n",
        "import requests\r\n",
        "import tarfile\r\n",
        "\r\n",
        "from shutil import copyfile\r\n",
        "\r\n",
        "\r\n",
        "os.chdir(PRE_TRAINED_MODELS_PATH)\r\n",
        "base_url = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/\"\r\n",
        "models = [\r\n",
        "          \"ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\",\r\n",
        "          # \"faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\"\r\n",
        "]\r\n",
        "\r\n",
        "for model in models:\r\n",
        "  url = base_url + model\r\n",
        "  r = requests.get(url, allow_redirects=True)\r\n",
        "  open(model, 'wb').write(r.content)\r\n",
        "  tar = tarfile.open(model)\r\n",
        "  tar.extractall()\r\n",
        "  tar.close()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwavK8KUK2iD"
      },
      "source": [
        "## 4. Copy Choosen Model to Training folder\r\n",
        "Finally, the object detection training pipeline must be configured. It defines which model and what parameters will be used for training. This is the last step before running training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51esqZC9L823",
        "outputId": "98a0aa40-4874-47db-a4a1-fa05c9e4233c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "CUSTOM_MODEL_NAME = models[0].partition('.')[0]\r\n",
        "CUSTOM_MODEL_NAME"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ssd_mobilenet_v2_320x320_coco17_tpu-8'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3c_dmb9lQce0",
        "outputId": "d866d989-4c33-4fec-8413-3f5ebc927f08"
      },
      "source": [
        "import os\r\n",
        "from shutil import copyfile\r\n",
        "\r\n",
        "os.chdir(WORKSPACE_PATH)\r\n",
        "os.mkdir(MODEL_PATH + '/' + CUSTOM_MODEL_NAME)\r\n",
        "\r\n",
        "copyfile(PRE_TRAINED_MODELS_PATH + '/' + CUSTOM_MODEL_NAME + '/pipeline.config', MODEL_PATH + '/' + CUSTOM_MODEL_NAME + '/pipeline.config')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/TensorFlow/workspace/models/ssd_mobilenet_v2_320x320_coco17_tpu-8/pipeline.config'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GygVpScXZKu"
      },
      "source": [
        "## 5. Updating Choosen Model Config file\r\n",
        "There will be multiple parameters that needs to be configured for the config file prior to training. We will use a Python script to shorten the process.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26n3VzuTZAmi"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from object_detection.utils import config_util\r\n",
        "from object_detection.protos import pipeline_pb2\r\n",
        "from google.protobuf import text_format"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-GgPm4eZFhI"
      },
      "source": [
        "CONFIG_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME+'/pipeline.config'"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUjycEqNZL4t"
      },
      "source": [
        "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0tUXV78ZP3G"
      },
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\r\n",
        "with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:                                                                                                                                                                                                                     \r\n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \r\n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljUWROs6ZVbp"
      },
      "source": [
        "# Number of label classes\r\n",
        "pipeline_config.model.ssd.num_classes = 15\r\n",
        "# Number of images\r\n",
        "pipeline_config.train_config.batch_size = 15 \r\n",
        "# Model checkpoint (Checkpoints capture the exact value of all parameters (tf.Variable objects) used by a model)\r\n",
        "pipeline_config.train_config.fine_tune_checkpoint = PRE_TRAINED_MODELS_PATH + '/' +CUSTOM_MODEL_NAME + '/checkpoint/ckpt-0' \r\n",
        "# Specify to train DETECTION model\r\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\r\n",
        "# Label map for train\r\n",
        "pipeline_config.train_input_reader.label_map_path= ANNOTATIONS_PATH + '/label_map.pbtxt'\r\n",
        "# TF records of train\r\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [ANNOTATIONS_PATH + '/train.record']\r\n",
        "# Label map for test\r\n",
        "pipeline_config.eval_input_reader[0].label_map_path = ANNOTATIONS_PATH + '/label_map.pbtxt'\r\n",
        "# TF reocrds of test\r\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [ANNOTATIONS_PATH + '/test.record']"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCF9YHv9bZ1g"
      },
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \r\n",
        "with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:                                                                                                                                                                                                                     \r\n",
        "    f.write(config_text)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku2StgFgcWy5"
      },
      "source": [
        "## Train the Model\r\n",
        "Note TensorFlow 2 is used\r\n",
        "Number of training steps can be configured to suit the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai8YrnTbbi9O",
        "outputId": "9715afc0-fc52-49aa-a5d9-e57e8ca483f5"
      },
      "source": [
        "# --num_train_steps=5000\r\n",
        "print(\"\"\"!python {}/research/object_detection/model_main_tf2.py --model_dir={}/{} --pipeline_config_path={}/{}/pipeline.config \"\"\".format(TF_API_MODEL_PATH, MODEL_PATH,CUSTOM_MODEL_NAME,MODEL_PATH,CUSTOM_MODEL_NAME))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!python /content/TensorFlow/models/research/object_detection/model_main_tf2.py --model_dir=/content/TensorFlow/workspace/models/ssd_mobilenet_v2_320x320_coco17_tpu-8 --pipeline_config_path=/content/TensorFlow/workspace/models/ssd_mobilenet_v2_320x320_coco17_tpu-8/pipeline.config \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTEJrBdjdUX-",
        "outputId": "d7953753-e607-49df-ba88-28e2e9a03321"
      },
      "source": [
        "# run the printed statement ^^^^\r\n",
        "!python /content/TensorFlow/models/research/object_detection/model_main_tf2.py --model_dir=/content/TensorFlow/workspace/models/ssd_mobilenet_v2_320x320_coco17_tpu-8 --pipeline_config_path=/content/TensorFlow/workspace/models/ssd_mobilenet_v2_320x320_coco17_tpu-8/pipeline.config \r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-16 08:04:46.303804: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-16 08:04:48.706147: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-02-16 08:04:48.707013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-02-16 08:04:48.736704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 08:04:48.737296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-02-16 08:04:48.737332: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-16 08:04:48.738914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
            "2021-02-16 08:04:48.738995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
            "2021-02-16 08:04:48.740808: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-02-16 08:04:48.741147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-02-16 08:04:48.742945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-02-16 08:04:48.743835: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-02-16 08:04:48.747615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-16 08:04:48.747738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 08:04:48.748324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 08:04:48.748858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-02-16 08:04:48.749262: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-02-16 08:04:48.749390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 08:04:48.749956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-02-16 08:04:48.749987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-16 08:04:48.750025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
            "2021-02-16 08:04:48.750051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
            "2021-02-16 08:04:48.750077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-02-16 08:04:48.750097: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-02-16 08:04:48.750117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-02-16 08:04:48.750140: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-02-16 08:04:48.750164: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-02-16 08:04:48.750235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 08:04:48.750829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 08:04:48.751337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-02-16 08:04:48.751375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-02-16 08:04:49.264361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-02-16 08:04:49.264421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-02-16 08:04:49.264438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-02-16 08:04:49.264661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 08:04:49.265369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 08:04:49.265966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-02-16 08:04:49.266465: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-02-16 08:04:49.266511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13994 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0216 08:04:49.268213 139893204600704 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0216 08:04:49.272909 139893204600704 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0216 08:04:49.273077 139893204600704 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py:531: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0216 08:04:49.347105 139893204600704 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py:531: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/TensorFlow/workspace/annotations/train.record']\n",
            "I0216 08:04:49.360615 139893204600704 dataset_builder.py:163] Reading unweighted datasets: ['/content/TensorFlow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/TensorFlow/workspace/annotations/train.record']\n",
            "I0216 08:04:49.360821 139893204600704 dataset_builder.py:80] Reading record datasets for input file: ['/content/TensorFlow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0216 08:04:49.360910 139893204600704 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0216 08:04:49.360983 139893204600704 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0216 08:04:49.368633 139893204600704 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0216 08:04:49.390656 139893204600704 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0216 08:04:55.317437 139893204600704 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0216 08:04:58.374747 139893204600704 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0216 08:05:00.527956 139893204600704 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-02-16 08:05:02.630686: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-02-16 08:05:02.637305: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 08:05:09.537750 139889594287872 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 08:05:09.538028 139889594287872 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 08:05:09.538177 139889594287872 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 08:05:09.538311 139889594287872 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 08:05:09.538442 139889594287872 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0216 08:05:09.538589 139889594287872 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "2021-02-16 08:05:22.481238: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
            "2021-02-16 08:05:23.916526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._groundtruth_lists\n",
            "W0216 08:05:30.111518 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._groundtruth_lists\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor\n",
            "W0216 08:05:30.111860 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\n",
            "W0216 08:05:30.111953 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._batched_prediction_tensor_names\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads\n",
            "W0216 08:05:30.112025 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._sorted_head_names\n",
            "W0216 08:05:30.112089 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._sorted_head_names\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._shared_nets\n",
            "W0216 08:05:30.112151 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._shared_nets\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings\n",
            "W0216 08:05:30.112219 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background\n",
            "W0216 08:05:30.112278 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.0\n",
            "W0216 08:05:30.112338 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.1\n",
            "W0216 08:05:30.112396 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.2\n",
            "W0216 08:05:30.112465 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.3\n",
            "W0216 08:05:30.112525 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.3\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.4\n",
            "W0216 08:05:30.112594 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.4\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.5\n",
            "W0216 08:05:30.112653 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._shared_nets.5\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0\n",
            "W0216 08:05:30.112722 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1\n",
            "W0216 08:05:30.112781 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2\n",
            "W0216 08:05:30.112842 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3\n",
            "W0216 08:05:30.112900 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4\n",
            "W0216 08:05:30.112962 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5\n",
            "W0216 08:05:30.113019 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0\n",
            "W0216 08:05:30.113077 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1\n",
            "W0216 08:05:30.113137 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2\n",
            "W0216 08:05:30.113194 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3\n",
            "W0216 08:05:30.113253 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4\n",
            "W0216 08:05:30.113311 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5\n",
            "W0216 08:05:30.113368 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers\n",
            "W0216 08:05:30.113471 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers\n",
            "W0216 08:05:30.113535 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers\n",
            "W0216 08:05:30.113615 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers\n",
            "W0216 08:05:30.113674 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers\n",
            "W0216 08:05:30.113733 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers\n",
            "W0216 08:05:30.113790 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers\n",
            "W0216 08:05:30.113847 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers\n",
            "W0216 08:05:30.113906 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers\n",
            "W0216 08:05:30.113970 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers\n",
            "W0216 08:05:30.114028 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers\n",
            "W0216 08:05:30.114085 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers\n",
            "W0216 08:05:30.114144 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0\n",
            "W0216 08:05:30.114204 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers.0\n",
            "W0216 08:05:30.114262 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers.0\n",
            "W0216 08:05:30.114319 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers.0\n",
            "W0216 08:05:30.114376 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers.0\n",
            "W0216 08:05:30.114433 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers.0\n",
            "W0216 08:05:30.114490 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0\n",
            "W0216 08:05:30.114549 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers.0\n",
            "W0216 08:05:30.114628 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers.0\n",
            "W0216 08:05:30.114685 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers.0\n",
            "W0216 08:05:30.114743 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers.0\n",
            "W0216 08:05:30.114801 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers.0\n",
            "W0216 08:05:30.114859 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers.0\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.kernel\n",
            "W0216 08:05:30.114929 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.bias\n",
            "W0216 08:05:30.114987 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.0._box_encoder_layers.0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers.0.kernel\n",
            "W0216 08:05:30.115044 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers.0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers.0.bias\n",
            "W0216 08:05:30.115102 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.1._box_encoder_layers.0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers.0.kernel\n",
            "W0216 08:05:30.115159 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers.0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers.0.bias\n",
            "W0216 08:05:30.115215 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.2._box_encoder_layers.0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers.0.kernel\n",
            "W0216 08:05:30.115272 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers.0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers.0.bias\n",
            "W0216 08:05:30.115328 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.3._box_encoder_layers.0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers.0.kernel\n",
            "W0216 08:05:30.115387 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers.0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers.0.bias\n",
            "W0216 08:05:30.115449 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.4._box_encoder_layers.0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers.0.kernel\n",
            "W0216 08:05:30.204953 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers.0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers.0.bias\n",
            "W0216 08:05:30.205086 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.box_encodings.5._box_encoder_layers.0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.kernel\n",
            "W0216 08:05:30.205193 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.bias\n",
            "W0216 08:05:30.205287 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.0._class_predictor_layers.0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers.0.kernel\n",
            "W0216 08:05:30.205372 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers.0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers.0.bias\n",
            "W0216 08:05:30.205454 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.1._class_predictor_layers.0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers.0.kernel\n",
            "W0216 08:05:30.205535 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers.0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers.0.bias\n",
            "W0216 08:05:30.205639 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.2._class_predictor_layers.0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers.0.kernel\n",
            "W0216 08:05:30.205716 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers.0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers.0.bias\n",
            "W0216 08:05:30.205794 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.3._class_predictor_layers.0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers.0.kernel\n",
            "W0216 08:05:30.205873 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers.0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers.0.bias\n",
            "W0216 08:05:30.205967 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.4._class_predictor_layers.0.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers.0.kernel\n",
            "W0216 08:05:30.206048 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers.0.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers.0.bias\n",
            "W0216 08:05:30.206127 139893204600704 util.py:161] Unresolved object in checkpoint: (root).model._box_predictor._prediction_heads.class_predictions_with_background.5._class_predictor_layers.0.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "W0216 08:05:30.206208 139893204600704 util.py:169] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0216 08:05:30.884618 139893204600704 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0216 08:05:30.885848 139893204600704 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0216 08:05:30.887607 139893204600704 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0216 08:05:30.888329 139893204600704 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0216 08:05:30.890047 139893204600704 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0216 08:05:30.890802 139893204600704 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0216 08:05:30.892475 139893204600704 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0216 08:05:30.893225 139893204600704 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0216 08:05:30.894928 139893204600704 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0216 08:05:30.895669 139893204600704 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0216 08:05:36.480713 139892493002496 deprecation.py:537] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 0.220s loss=0.699\n",
            "I0216 08:06:09.452898 139893204600704 model_lib_v2.py:659] Step 100 per-step time 0.220s loss=0.699\n",
            "INFO:tensorflow:Step 200 per-step time 0.218s loss=0.434\n",
            "I0216 08:06:31.435997 139893204600704 model_lib_v2.py:659] Step 200 per-step time 0.218s loss=0.434\n",
            "INFO:tensorflow:Step 300 per-step time 0.219s loss=0.480\n",
            "I0216 08:06:53.469202 139893204600704 model_lib_v2.py:659] Step 300 per-step time 0.219s loss=0.480\n",
            "INFO:tensorflow:Step 400 per-step time 0.199s loss=0.322\n",
            "I0216 08:07:15.972863 139893204600704 model_lib_v2.py:659] Step 400 per-step time 0.199s loss=0.322\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}